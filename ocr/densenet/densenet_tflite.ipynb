{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:38.992213400Z",
     "start_time": "2023-12-12T07:13:32.708119Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import get_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Lambda, Reshape\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def preprocess_image_layer():\n",
    "    def single_img_process_tf(img):\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "\n",
    "        original_shape = tf.shape(img)\n",
    "        original_height = original_shape[1]\n",
    "        original_width = original_shape[2]\n",
    "        new_width = original_width * 32 // original_height\n",
    "\n",
    "        img = tf.image.resize(img, [32, new_width])\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        img = img / 255.0 - 0.5\n",
    "\n",
    "        img = tf.expand_dims(img, -1)\n",
    "\n",
    "        return img\n",
    "\n",
    "    return Lambda(single_img_process_tf, name='preprocessing_layer')\n",
    "\n",
    "# Load your existing model\n",
    "predict_model, train_model = get_model()\n",
    "\n",
    "# Create a new model that includes the preprocessing layer\n",
    "model_with_preprocessing = Sequential([\n",
    "    preprocess_image_layer(),\n",
    "    predict_model\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:44.329163500Z",
     "start_time": "2023-12-12T07:13:38.992213400Z"
    }
   },
   "id": "5181b7f021eb3fcd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " preprocessing_layer (Lambda  (None, 32, None, 1, 1)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " model (Functional)          (None, None, 5991)        4897511   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,897,511\n",
      "Trainable params: 4,890,023\n",
      "Non-trainable params: 7,488\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save\\assets\n"
     ]
    }
   ],
   "source": [
    "model_with_preprocessing.build((None, None, None, 3))\n",
    "model_with_preprocessing.summary()\n",
    "\n",
    "tf.saved_model.save(model_with_preprocessing, 'save')\n",
    "\n",
    "# 转化为tflite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model_with_preprocessing)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('save')\n",
    "converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TFLite ops\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS,  # enable TF ops\n",
    "    ]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('save_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "#保存tflite\n",
    "# with open('densenet.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:56.147666600Z",
     "start_time": "2023-12-12T07:13:44.329163500Z"
    }
   },
   "id": "84bf53ddebac02de"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Lite model: D:\\ProgramData\\IO\\mt-io\\ocr\\densenet\\save_model.tflite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'save_model.tflite')\n",
    "print('TF Lite model:', model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:56.172201400Z",
     "start_time": "2023-12-12T07:13:56.147666600Z"
    }
   },
   "id": "a23acd827562a8df"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_preprocessing_layer_input:0', 'index': 0, 'shape': array([1, 1, 1, 3]), 'shape_signature': array([-1, -1, -1,  3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "(10, 5991)\n",
      "[[0.00019616 0.00019973 0.00018511 ... 0.00017426 0.0002028  0.0001398 ]\n",
      " [0.00019408 0.00021143 0.00017693 ... 0.00016959 0.00018444 0.00013365]\n",
      " [0.00019141 0.00020878 0.00017289 ... 0.00016279 0.00018847 0.00014025]\n",
      " ...\n",
      " [0.00019257 0.00020875 0.00017403 ... 0.00016126 0.00018833 0.00014149]\n",
      " [0.00019874 0.00020396 0.00017802 ... 0.00016521 0.00018433 0.00014263]\n",
      " [0.00020595 0.00021229 0.00016106 ... 0.00015685 0.00017544 0.00014268]]\n"
     ]
    }
   ],
   "source": [
    "input_image = tf.random.normal(shape=(1, 200, 500, 3), dtype=tf.float32)\n",
    "# Run inference with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], (1, 200, 500, 3), strict=True)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(input_details[0][\"index\"], input_image)\n",
    "\n",
    "print(input_details)\n",
    "\n",
    "interpreter.invoke()\n",
    "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])()[0]\n",
    "print(output.shape)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:56.212088700Z",
     "start_time": "2023-12-12T07:13:56.163706700Z"
    }
   },
   "id": "830b77fb1b2f058"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:13:56.227130600Z",
     "start_time": "2023-12-12T07:13:56.212088700Z"
    }
   },
   "id": "19ef72f651bb1f12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
